{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f27e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn, device, no_grad\n",
    "import torch.cuda\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d784480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(\"../data/train_labels.csv\")\n",
    "image_folder = \"../data/Train/\"\n",
    "label_encoder = LabelEncoder()\n",
    "labels[\"label\"] = label_encoder.fit_transform(labels[\"label\"])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "766acf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_pokemon(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    gray_img = img.convert(\"L\") # Convert to grayscale\n",
    "    img_array = np.array(gray_img)\n",
    "\n",
    "    # Detect black silhouette (thresholding)\n",
    "    threshold = 3  # Adjust this value if needed, provavelmente 3/4/5 é o melhor, 3 fico 95% mas ha 1 ou outro estranho\n",
    "    mask = img_array < threshold\n",
    "\n",
    "    # Get coordinates of silhouette (bounding box)\n",
    "    coords = np.column_stack(np.where(mask))\n",
    "\n",
    "    y_min, x_min = coords.min(axis=0)\n",
    "    y_max, x_max = coords.max(axis=0)\n",
    "\n",
    "    # Apply padding (5%)\n",
    "    pad = int(0.05 * min(x_max - x_min, y_max - y_min))\n",
    "    x_min, y_min = max(0, x_min - pad), max(0, y_min - pad)\n",
    "    x_max, y_max = min(img.width, x_max + pad), min(img.height, y_max + pad)\n",
    "\n",
    "    cropped_img = img.crop((x_min, y_min, x_max, y_max))\n",
    "    \n",
    "    #Fill it back to 64x64 with transparent pixels\n",
    "    width, height = cropped_img.size\n",
    "    new_img = Image.new(\"RGBA\", (64, 64), (0, 0, 0, 0))\n",
    "    x_offset = (64 - width) // 2\n",
    "    y_offset = (64 - height) // 2\n",
    "    new_img.paste(cropped_img, (x_offset, y_offset))\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7efd2867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class definition assuming cropped training and uncropped testing\n",
    "class PokemonDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_name = os.path.join(self.img_dir, str(self.df.iloc[idx, 0]))\n",
    "        if not img_name.endswith('.png'):\n",
    "            img_name += \".png\"\n",
    "            image = Image.open(img_name)\n",
    "        else:\n",
    "            image = Image.open(img_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(Image.open(img_name))\n",
    "\n",
    "        if len(self.df.columns) > 1:  # Train Set has labels, Test does not.\n",
    "            label = self.df.iloc[idx, 1]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, -1  # X dont care for Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d36d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes, dropout=0.3):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # At this point: 64x64 → 32x32 → 16x16 → 8x8 → 4x4\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool4(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e74ffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for better generalization\n",
    "transform = transforms.Compose([\n",
    "    #transforms.RandomHorizontalFlip(), # Random flipping left-right\n",
    "    #transforms.RandomRotation(15), # Rotate randomly within ±15 degrees\n",
    "    #transforms.ColorJitter(brightness=0.2, contrast=0.2), # Adjust brightness/contrast\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5, 0.0], std=[0.5, 0.5, 0.5, 1.0])\n",
    "    #transforms.Lambda(lambda x: x.view(-1))  # Flatten\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8e489c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 3 (70% train, 10% val, 20% test)\n",
    "dataset = PokemonDataset(labels, image_folder, transform)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2371a42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf01f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "n_epochs = 120\n",
    "learning_rate = 0.001\n",
    "\n",
    "early_stop_epochs=30\n",
    "early_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c18ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7833b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72bbc5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 2.0531, F1 Score: 0.1929\n",
      "Epoch [2/50], Loss: 1.7590, F1 Score: 0.1842\n",
      "Epoch [3/50], Loss: 1.6107, F1 Score: 0.2551\n",
      "Epoch [4/50], Loss: 1.3322, F1 Score: 0.4248\n",
      "Epoch [5/50], Loss: 1.1727, F1 Score: 0.2513\n",
      "Epoch [6/50], Loss: 0.9732, F1 Score: 0.2774\n",
      "Epoch [7/50], Loss: 0.8861, F1 Score: 0.5468\n",
      "Epoch [8/50], Loss: 0.7637, F1 Score: 0.5690\n",
      "Epoch [9/50], Loss: 0.6532, F1 Score: 0.6169\n",
      "Epoch [10/50], Loss: 0.5830, F1 Score: 0.7328\n",
      "Epoch [11/50], Loss: 0.4532, F1 Score: 0.8432\n",
      "Epoch [12/50], Loss: 0.4519, F1 Score: 0.8803\n",
      "Epoch [13/50], Loss: 0.3395, F1 Score: 0.9110\n",
      "Epoch [14/50], Loss: 0.2682, F1 Score: 0.8073\n",
      "Epoch [15/50], Loss: 0.2894, F1 Score: 0.9034\n",
      "Epoch [16/50], Loss: 0.2228, F1 Score: 0.7708\n",
      "Epoch [17/50], Loss: 0.2517, F1 Score: 0.8451\n",
      "Epoch [18/50], Loss: 0.2608, F1 Score: 0.6175\n",
      "Epoch [19/50], Loss: 0.1542, F1 Score: 0.8239\n",
      "Epoch [20/50], Loss: 0.2463, F1 Score: 0.9771\n",
      "Epoch [21/50], Loss: 0.1663, F1 Score: 0.7475\n",
      "Epoch [22/50], Loss: 0.1641, F1 Score: 0.7892\n",
      "Epoch [23/50], Loss: 0.1876, F1 Score: 0.7286\n",
      "Epoch [24/50], Loss: 0.1230, F1 Score: 0.8744\n",
      "Epoch [25/50], Loss: 0.1170, F1 Score: 0.9571\n",
      "Epoch [26/50], Loss: 0.0659, F1 Score: 0.9811\n",
      "Epoch [27/50], Loss: 0.0665, F1 Score: 0.9662\n",
      "Epoch [28/50], Loss: 0.0408, F1 Score: 1.0000\n",
      "Epoch [29/50], Loss: 0.1248, F1 Score: 0.8595\n",
      "Epoch [30/50], Loss: 0.1345, F1 Score: 0.7625\n",
      "Epoch [31/50], Loss: 0.1245, F1 Score: 0.9945\n",
      "Epoch [32/50], Loss: 0.0546, F1 Score: 0.8942\n",
      "Epoch [33/50], Loss: 0.0738, F1 Score: 0.9803\n",
      "Epoch [34/50], Loss: 0.1121, F1 Score: 0.8676\n",
      "Epoch [35/50], Loss: 0.0869, F1 Score: 0.9944\n",
      "Epoch [36/50], Loss: 0.0944, F1 Score: 0.9070\n",
      "Epoch [37/50], Loss: 0.0625, F1 Score: 0.9590\n",
      "Epoch [38/50], Loss: 0.0788, F1 Score: 0.9889\n",
      "Epoch [39/50], Loss: 0.0237, F1 Score: 0.9969\n",
      "Epoch [40/50], Loss: 0.1001, F1 Score: 0.9867\n",
      "Epoch [41/50], Loss: 0.0902, F1 Score: 0.9831\n",
      "Epoch [42/50], Loss: 0.0722, F1 Score: 0.9947\n",
      "Epoch [43/50], Loss: 0.0228, F1 Score: 0.9957\n",
      "Epoch [44/50], Loss: 0.0374, F1 Score: 0.9770\n",
      "Epoch [45/50], Loss: 0.0563, F1 Score: 0.9736\n",
      "Epoch [46/50], Loss: 0.0968, F1 Score: 0.9955\n",
      "Epoch [47/50], Loss: 0.0444, F1 Score: 0.9699\n",
      "Epoch [48/50], Loss: 0.1349, F1 Score: 0.9899\n",
      "Epoch [49/50], Loss: 0.0690, F1 Score: 0.9956\n",
      "Epoch [50/50], Loss: 0.0195, F1 Score: 1.0000\n",
      "Execution time: 1511.6472594738007 seconds\n",
      "Test Accuracy: 100.00%\n",
      "Test F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  for images, labels in train_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "  # Validation loop\n",
    "  model.eval()\n",
    "  all_labels = []\n",
    "  all_preds = []\n",
    "  with no_grad():\n",
    "    for images, labels in val_loader:\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      outputs = model(images)\n",
    "      _, preds = torch.max(outputs, 1)  # Get predicted class indices\n",
    "      all_labels.extend(labels.cpu().numpy())\n",
    "      all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "  # Calculate F1 Score\n",
    "  f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "  print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {running_loss/len(train_loader):.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "  #if (f1 > 0.800) and not early_stop:\n",
    "   # epoch = n_epochs - early_stop_epochs\n",
    "    #early_stop = True\n",
    "    #print(\"Early stop on epoch \", epoch)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")\n",
    "\n",
    "# Test loop\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "with no_grad():\n",
    "  for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    all_labels.extend(labels.cpu().numpy())\n",
    "    all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5949148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for better testing\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5, 0.0], std=[0.5, 0.5, 0.5, 1.0])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaa631cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test folder path for predictions\n",
    "test_folder = \"../data/Test\"\n",
    "\n",
    "# Create the Test dataset (without labels)\n",
    "test_files = os.listdir(test_folder)\n",
    "test_files = [f for f in test_files if f.endswith('.png')]  # Assuming PNG format for test images\n",
    "\n",
    "# Create a DataFrame to hold the test file names (Ids)\n",
    "test_df = pd.DataFrame({'Id': test_files})  # Only filenames (Ids)\n",
    "\n",
    "# Create PokemonDataset for test images (no labels)\n",
    "test_dataset = PokemonDataset(test_df, test_folder, transform=test_transform)\n",
    "\n",
    "# Create DataLoader for test data\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db02627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test dataset\n",
    "predictions = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:  # No labels in test set\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)  # Get predicted class indices\n",
    "        predictions.extend(preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ab71561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'Id': [file.split('.')[0] for file in test_files],  # extract id\n",
    "    'Category': label_encoder.inverse_transform(predictions)  \n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv(\"task2_submit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e2ef72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
