{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4bCVXcWfGEB",
        "outputId": "fb169411-64a9-46a3-e7ed-013e8c32d1c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m692.3/692.3 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install mlflow torchmetrics torchinfo --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8awIoMCWEM6o",
        "outputId": "e5975aaa-1b48-4393-e182-58889fe62e20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=01d13b7d9e65efeef84e4e12a40f3a70d415ad01eb0ce5b3bd3a1ebce545ebd6\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install GPUtil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RZbzxjigLi3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pprint\n",
        "\n",
        "from random import random, randint\n",
        "from mlflow import log_metric, log_param, log_artifacts\n",
        "from mlflow.tracking import MlflowClient\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchinfo import summary\n",
        "from torchmetrics import Accuracy, F1Score\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.nn.functional as F\n",
        "#import tensorflow as tf\n",
        "import GPUtil\n",
        "from collections import deque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGpJwvIrgNfR",
        "outputId": "70b7a2ed-227a-469b-b097-91a7a1673398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkmsPCUehG9g",
        "outputId": "356f5a66-73ff-4f3d-c4ac-883bea950302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.21.3\n"
          ]
        }
      ],
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "print(mlflow.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKP3nB69hKCC",
        "outputId": "694b9cbf-bea1-4a84-ce70-740348c9704f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.21.3\n"
          ]
        }
      ],
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "print(mlflow.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx7d5anUhRk5",
        "outputId": "5f4bc863-e0b9-4563-8791-0622e82dc2ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train_labels.csv', 'Test', 'Train', 'TrainCropped']\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "folder_path = '/content/drive/MyDrive/ap_proj1'\n",
        "files_in_folder = os.listdir(folder_path + \"/data\")\n",
        "print(files_in_folder)\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TehegcFdhWcN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e807bf6-2384-4e88-f5dc-4b95609dfe1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ],
      "source": [
        "labels = pd.read_csv(folder_path + \"/data/train_labels.csv\")\n",
        "image_folder = folder_path + \"/data/Train/\"\n",
        "label_encoder = LabelEncoder()\n",
        "labels[\"label\"] = label_encoder.fit_transform(labels[\"label\"])\n",
        "num_classes = len(label_encoder.classes_)\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCA5OEkNtby6",
        "outputId": "2a590b26-5b20-4019-9495-beb2a701ecd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='/content/mlruns/3', creation_time=1744459292020, experiment_id='3', last_update_time=1744459292020, lifecycle_stage='active', name='/task2', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "get_ipython().system_raw(\"mlflow ui --backend-store-uri sqlite:///drive/MyDrive/ap_proj1/mlflowdata/mlruns.db --port 5000 &\")# run tracking UI in the background\n",
        "local_registry = \"sqlite:///drive/MyDrive/ap_proj1/mlflowdata/mlruns.db\"\n",
        "model_name=\"CNN\"\n",
        "mlflow.set_tracking_uri(local_registry)\n",
        "mlflow.set_experiment(\"/task2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C84KlWI04U-r",
        "outputId": "8bd082cb-ef8e-4dfb-8ca5-c8367f13ade2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.4-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.4-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIqKIeCwthLH"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J0mMXjltiSS"
      },
      "outputs": [],
      "source": [
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROkj4AeltkKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c054eb-0e00-4940-fc6b-b8626b6186f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "NGROK_AUTH_TOKEN = \"2uryxEZ5QrQQ0SGn8gTWLAAT1ei_7Njezw5fQYwuwdb4mfhpk\" # <- Paste your token here\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOrXX3eUtm8v",
        "outputId": "36c70246-3e0d-41de-da69-c0c534ccdea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Tracking UI: NgrokTunnel: \"https://ec94-35-197-92-10.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ],
      "source": [
        "public_url = ngrok.connect(\"5000\")\n",
        "print(\"MLflow Tracking UI:\", public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvAvvCHgh24_"
      },
      "outputs": [],
      "source": [
        "class PokemonDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_name = os.path.join(self.img_dir, str(self.df.iloc[idx, 0]))\n",
        "        if not img_name.endswith('.png'):\n",
        "            img_name += \".png\"\n",
        "            image = Image.open(img_name)\n",
        "        else:\n",
        "            image = Image.open(img_name)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(Image.open(img_name))\n",
        "\n",
        "        if len(self.df.columns) > 1:  # Train Set has labels, Test does not.\n",
        "            label = self.df.iloc[idx, 1]\n",
        "            return image, label\n",
        "        else:\n",
        "            return image, -1  # X dont care for Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWeIlm3Ph8yd"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes, dropout=0.3):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(4, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # At this point: 64x64 → 32x32 → 16x16 → 8x8 → 4x4\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool4(F.relu(self.bn4(self.conv4(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNEntWEllnTv"
      },
      "outputs": [],
      "source": [
        "# Define transformations for better generalization\n",
        "transform = transforms.Compose([\n",
        "    #transforms.RandomHorizontalFlip(), # Random flipping left-right\n",
        "    #transforms.RandomRotation(15), # Rotate randomly within ±15 degrees\n",
        "    #transforms.ColorJitter(brightness=0.2, contrast=0.2), # Adjust brightness/contrast\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5, 0.0], std=[0.5, 0.5, 0.5, 1.0])\n",
        "    #transforms.Lambda(lambda x: x.view(-1))  # Flatten\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KvaVlSnlpZ2"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into 3 (70% train, 10% val, 20% test)\n",
        "dataset = PokemonDataset(labels, image_folder, transform=transform)\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3Xks2p8lsf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c07b53-5b5a-41b0-e6be-ae75d026629f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9jGeOKvskGD"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "n_epochs = 80\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9PDZUyLsoP6",
        "outputId": "80efc263-40c5-421b-b239-ffe35b910dde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc1): Linear(in_features=4096, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "model = CNN(num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "pip_requirements = [\"torch==2.6.0+cu124\"]\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1P975xls0vv"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQmrzfQLD_Dr"
      },
      "outputs": [],
      "source": [
        "def log_gpu_usage():\n",
        "    gpus = GPUtil.getGPUs()\n",
        "    for i, gpu in enumerate(gpus):\n",
        "        mlflow.log_metric(f\"gpu_{i}_memory_used_MB\", gpu.memoryUsed)\n",
        "        mlflow.log_metric(f\"gpu_{i}_memory_total_MB\", gpu.memoryTotal)\n",
        "        mlflow.log_metric(f\"gpu_{i}_utilization_percent\", gpu.load * 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_1YNnzE2YWF"
      },
      "outputs": [],
      "source": [
        "# Function to check stopping condition\n",
        "def early_stop(queue):\n",
        "    if len(queue) < 5:\n",
        "        return False  # Not enough data yet\n",
        "\n",
        "    scores = np.array(queue)\n",
        "    max_score = np.max(scores)\n",
        "    min_score = np.min(scores)\n",
        "\n",
        "    # Relative difference\n",
        "    if max_score == 0:\n",
        "        return False  # avoid division by zero\n",
        "\n",
        "    relative_change = (max_score - min_score) / max_score\n",
        "\n",
        "    return relative_change < 0.02  # less than 2% change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35BmX7XwbNO9"
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "def training_loop():\n",
        "    f1_queue = deque(maxlen=5)\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item()\n",
        "\n",
        "          log_gpu_usage()\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "        with torch.no_grad():\n",
        "          for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)  # Get predicted class indices\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "        # Calculate F1 Score\n",
        "        f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "        f1_queue.append(f1)\n",
        "        print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {running_loss/len(train_loader):.4f}, F1 Score: {f1:.4f}\")\n",
        "        mlflow.log_metric(\"loss\", f\"{running_loss/len(train_loader):.4f}\")\n",
        "        mlflow.log_metric(\"f1_score\", f\"{f1:.4f}\")\n",
        "        if early_stop(f1_queue):\n",
        "            print(\"Early stopping triggered: F1 score change < 2% over last 5 epochs.\")\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    print(f\"Execution time: {execution_time} seconds\")\n",
        "\n",
        "    # Test loop\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    mlflow.log_metric(\"eval_loss\", f\"{running_loss/len(train_loader):.4f}\")\n",
        "    mlflow.log_metric(\"eval_accuracy\", f\"{f1:.4f}\")\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Test F1 Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDpx6gDIxM21",
        "outputId": "9bffd9df-5b50-4835-8f7e-b2dd6b645b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/80], Loss: 2.0462, F1 Score: 0.2486\n",
            "Epoch [2/80], Loss: 1.7629, F1 Score: 0.2588\n",
            "Epoch [3/80], Loss: 1.6564, F1 Score: 0.3271\n",
            "Epoch [4/80], Loss: 1.4790, F1 Score: 0.3636\n",
            "Epoch [5/80], Loss: 1.2439, F1 Score: 0.3562\n",
            "Epoch [6/80], Loss: 1.1346, F1 Score: 0.5768\n",
            "Epoch [7/80], Loss: 1.0018, F1 Score: 0.3458\n",
            "Epoch [8/80], Loss: 0.8941, F1 Score: 0.4440\n",
            "Epoch [9/80], Loss: 0.8302, F1 Score: 0.6726\n",
            "Epoch [10/80], Loss: 0.7216, F1 Score: 0.5907\n",
            "Epoch [11/80], Loss: 0.6265, F1 Score: 0.7052\n",
            "Epoch [12/80], Loss: 0.5035, F1 Score: 0.7712\n",
            "Epoch [13/80], Loss: 0.4790, F1 Score: 0.5319\n",
            "Epoch [14/80], Loss: 0.4386, F1 Score: 0.6701\n",
            "Epoch [15/80], Loss: 0.3158, F1 Score: 0.8730\n",
            "Epoch [16/80], Loss: 0.2885, F1 Score: 0.4780\n",
            "Epoch [17/80], Loss: 0.2955, F1 Score: 0.6166\n",
            "Epoch [18/80], Loss: 0.2356, F1 Score: 0.8996\n",
            "Epoch [19/80], Loss: 0.1634, F1 Score: 0.9129\n",
            "Epoch [20/80], Loss: 0.1943, F1 Score: 0.9747\n",
            "Epoch [21/80], Loss: 0.1864, F1 Score: 0.6219\n",
            "Epoch [22/80], Loss: 0.1564, F1 Score: 0.7722\n",
            "Epoch [23/80], Loss: 0.1689, F1 Score: 0.7776\n",
            "Epoch [24/80], Loss: 0.2347, F1 Score: 0.7754\n",
            "Epoch [25/80], Loss: 0.1187, F1 Score: 0.8517\n",
            "Epoch [26/80], Loss: 0.1353, F1 Score: 0.9914\n",
            "Epoch [27/80], Loss: 0.1173, F1 Score: 0.9022\n",
            "Epoch [28/80], Loss: 0.0839, F1 Score: 0.9897\n",
            "Epoch [29/80], Loss: 0.1122, F1 Score: 0.9906\n",
            "Epoch [30/80], Loss: 0.0819, F1 Score: 0.9697\n",
            "Epoch [31/80], Loss: 0.0830, F1 Score: 0.9801\n",
            "Epoch [32/80], Loss: 0.0551, F1 Score: 0.9472\n",
            "Epoch [33/80], Loss: 0.1449, F1 Score: 0.8676\n",
            "Epoch [34/80], Loss: 0.0768, F1 Score: 0.9917\n",
            "Epoch [35/80], Loss: 0.0409, F1 Score: 0.9910\n",
            "Epoch [36/80], Loss: 0.0742, F1 Score: 0.9782\n",
            "Epoch [37/80], Loss: 0.0618, F1 Score: 0.9955\n",
            "Epoch [38/80], Loss: 0.0991, F1 Score: 0.9385\n",
            "Epoch [39/80], Loss: 0.0813, F1 Score: 0.9880\n",
            "Epoch [40/80], Loss: 0.0421, F1 Score: 0.9885\n",
            "Epoch [41/80], Loss: 0.0591, F1 Score: 0.9951\n",
            "Epoch [42/80], Loss: 0.0761, F1 Score: 0.9263\n",
            "Epoch [43/80], Loss: 0.1059, F1 Score: 0.9686\n",
            "Epoch [44/80], Loss: 0.0778, F1 Score: 0.6945\n",
            "Epoch [45/80], Loss: 0.1365, F1 Score: 0.9890\n",
            "Epoch [46/80], Loss: 0.0214, F1 Score: 0.9895\n",
            "Epoch [47/80], Loss: 0.0466, F1 Score: 0.9859\n",
            "Epoch [48/80], Loss: 0.0226, F1 Score: 0.9933\n",
            "Epoch [49/80], Loss: 0.0195, F1 Score: 0.9895\n",
            "Early stopping triggered: F1 score change < 2% over last 5 epochs.\n",
            "Execution time: 2345.5000965595245 seconds\n",
            "Test Accuracy: 99.44%\n",
            "Test F1 Score: 0.9966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/14 22:11:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "with mlflow.start_run() as run:\n",
        "  params = {\n",
        "        \"epochs\": n_epochs,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"loss_function\": criterion.__class__.__name__,\n",
        "        \"metric_function\": f1_score.__name__,\n",
        "        \"optimizer\": \"Adam\"\n",
        "        #\"step_size\": step_size,\n",
        "        #\"layer1_size\": l1_size,\n",
        "        #\"layer2_size\": l2_size,\n",
        "        #\"dropout\": dropout,\n",
        "        #\"gamma\": gamma\n",
        "    }\n",
        "  output_folder = os.path.join(folder_path, \"outputs\")\n",
        "  if not os.path.exists(output_folder):\n",
        "      os.makedirs(output_folder)\n",
        "\n",
        "  # Log training parameters.\n",
        "  mlflow.log_params(params)\n",
        "\n",
        "  # Log model summary.\n",
        "  with open(os.path.join(output_folder, \"model_summary.txt\"), \"w\") as f:\n",
        "      f.write(str(summary(model)))\n",
        "\n",
        "  log_artifacts(output_folder)\n",
        "  mlflow.log_artifact(os.path.join(output_folder, \"model_summary.txt\"))\n",
        "\n",
        "  training_loop()\n",
        "\n",
        "  mlflow.pytorch.log_model(model, \"model\", pip_requirements=pip_requirements)#, input_example=sample_image.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "homUnka8bNO-",
        "outputId": "3a81dc86-e1ce-4d83-d1c3-09d42288e73e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of all registered models\n",
            "================================================================================\n",
            "{   'aliases': {},\n",
            "    'creation_timestamp': 1743092803691,\n",
            "    'description': None,\n",
            "    'last_updated_timestamp': 1743092803751,\n",
            "    'latest_versions': [   <ModelVersion: aliases=[], creation_timestamp=1743092803751, current_stage='None', description=None, last_updated_timestamp=1743092803751, name='MLP', run_id='b2e8bf02d84647068e8b6324abad84bf', run_link=None, source='/content/mlruns/1/b2e8bf02d84647068e8b6324abad84bf/artifacts/sklearn-model', status='READY', status_message=None, tags={}, user_id=None, version=1>],\n",
            "    'name': 'MLP',\n",
            "    'tags': {}}\n",
            "None\n",
            "\n",
            "List of Model = CNN and Versions\n",
            "================================================================================\n",
            "{   'aliases': [],\n",
            "    'creation_timestamp': 1743092803751,\n",
            "    'current_stage': 'None',\n",
            "    'description': None,\n",
            "    'last_updated_timestamp': 1743092803751,\n",
            "    'name': 'MLP',\n",
            "    'run_id': 'b2e8bf02d84647068e8b6324abad84bf',\n",
            "    'run_link': None,\n",
            "    'source': '/content/mlruns/1/b2e8bf02d84647068e8b6324abad84bf/artifacts/sklearn-model',\n",
            "    'status': 'READY',\n",
            "    'status_message': None,\n",
            "    'tags': {},\n",
            "    'user_id': None,\n",
            "    'version': 1}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "client = MlflowClient()\n",
        "\n",
        "print(\"List of all registered models\")\n",
        "print(\"=\" * 80)\n",
        "[print(pprint.pprint(dict(rm), indent=4)) for rm in client.search_registered_models()]\n",
        "\n",
        "# Get a list of specific versions of the named models\n",
        "print(f\"\\nList of Model = {model_name} and Versions\")\n",
        "print(\"=\" * 80)\n",
        "[pprint.pprint(dict(mv), indent=4) for mv in client.search_model_versions()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3rH6P_zRMul"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "APenv",
      "language": "python",
      "name": "apenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}