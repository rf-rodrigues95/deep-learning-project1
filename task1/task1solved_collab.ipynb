{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v4bCVXcWfGEB",
    "outputId": "3ddb3fca-4efd-4b45-e953-cbce6ab8a884"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.9/960.9 kB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m877.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m684.0/684.0 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install mlflow torchmetrics torchinfo --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8awIoMCWEM6o",
    "outputId": "ab7333bf-a0d4-44f9-9280-4f079cbc9067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GPUtil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: GPUtil\n",
      "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=68982009b2fa11a8861dda5b69f52a6dc9e5dfff878a41c8091e0daf5ea8ca84\n",
      "  Stored in directory: /root/.cache/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n",
      "Successfully built GPUtil\n",
      "Installing collected packages: GPUtil\n",
      "Successfully installed GPUtil-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RZbzxjigLi3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pprint\n",
    "\n",
    "from random import random, randint\n",
    "from mlflow import log_metric, log_param, log_artifacts\n",
    "from mlflow.tracking import MlflowClient\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "import GPUtil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qGpJwvIrgNfR",
    "outputId": "d2ef26f2-f3f3-493c-dc3f-f6809a840bfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rkmsPCUehG9g",
    "outputId": "35d68f0b-ca82-43eb-8ab0-9f0889830300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.21.2\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "print(mlflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WKP3nB69hKCC",
    "outputId": "8897318e-0658-4dd4-84c8-1e04aa298b51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.21.2\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "print(mlflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dx7d5anUhRk5",
    "outputId": "8776abec-8c61-4212-f44d-4bb4f567b3c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_labels.csv', 'Test', 'Train', 'TrainCropped']\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/content/drive/MyDrive/ap_proj1'\n",
    "files_in_folder = os.listdir(folder_path + \"/data\")\n",
    "print(files_in_folder)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TehegcFdhWcN"
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(folder_path + \"/data/train_labels.csv\")\n",
    "image_folder = folder_path + \"/data/TrainCropped/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmZUGMezhZAo"
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels[\"label\"] = label_encoder.fit_transform(labels[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EHpWhyLacq4d",
    "outputId": "d2067f83-ad26-454c-b98a-6398e086b509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(label_encoder.classes_)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iCA5OEkNtby6",
    "outputId": "9bf07df2-b92a-4966-e6e3-9b51e64944e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/31 12:00:18 INFO mlflow.tracking.fluent: Experiment with name '/task1' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/content/mlruns/2', creation_time=1743422418043, experiment_id='2', last_update_time=1743422418043, lifecycle_stage='active', name='/task1', tags={}>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ipython().system_raw(\"mlflow ui --backend-store-uri sqlite:///drive/MyDrive/ap_proj1/mlflowdata/mlruns.db --port 5000 &\")# run tracking UI in the background\n",
    "local_registry = \"sqlite:///drive/MyDrive/ap_proj1/mlflowdata/mlruns.db\"\n",
    "model_name=\"MLP\"\n",
    "mlflow.set_tracking_uri(local_registry)\n",
    "mlflow.set_experiment(\"/task1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LIqKIeCwthLH"
   },
   "outputs": [],
   "source": [
    "from pyngrok import ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8J0mMXjltiSS"
   },
   "outputs": [],
   "source": [
    "ngrok.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROkj4AeltkKp",
    "outputId": "dc944cf0-3fa8-4eba-8bde-0795f9ea2f2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "NGROK_AUTH_TOKEN = \"2uryxEZ5QrQQ0SGn8gTWLAAT1ei_7Njezw5fQYwuwdb4mfhpk\" # <- Paste your token here\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOrXX3eUtm8v",
    "outputId": "1dab6e87-c77d-4d3b-a467-5f9d2fa2c585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking UI: NgrokTunnel: \"https://7f6a-35-203-130-43.ngrok-free.app\" -> \"http://localhost:5000\"\n"
     ]
    }
   ],
   "source": [
    "public_url = ngrok.connect(\"5000\")\n",
    "print(\"MLflow Tracking UI:\", public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svOBzXMahd9X"
   },
   "outputs": [],
   "source": [
    "def crop_pokemon(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    gray_img = img.convert(\"L\") # Convert to grayscale\n",
    "    img_array = np.array(gray_img)\n",
    "\n",
    "    # Detect black silhouette (thresholding)\n",
    "    threshold = 10\n",
    "    mask = img_array < threshold\n",
    "\n",
    "    # Get coordinates of silhouette\n",
    "    coords = np.column_stack(np.where(mask))\n",
    "    if coords.shape[0] == 0:\n",
    "        return img.resize((64, 64))  # If no silhouette found, return resized image\n",
    "\n",
    "    y_min, x_min = coords.min(axis=0)\n",
    "    y_max, x_max = coords.max(axis=0)\n",
    "\n",
    "    # Apply padding (5%)\n",
    "    pad = int(0.05 * min(x_max - x_min, y_max - y_min))\n",
    "    x_min, y_min = max(0, x_min - pad), max(0, y_min - pad)\n",
    "    x_max, y_max = min(img.width, x_max + pad), min(img.height, y_max + pad)\n",
    "\n",
    "    cropped_img = img.crop((x_min, y_min, x_max, y_max))\n",
    "    cropped_img = cropped_img.resize((64, 64))\n",
    "\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvAvvCHgh24_"
   },
   "outputs": [],
   "source": [
    "class PokemonDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, str(self.df.iloc[idx, 0]) + \".png\")\n",
    "\n",
    "        #image = crop_pokemon(img_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(Image.open(img_name))\n",
    "\n",
    "        if len(self.df.columns) > 1:  # Train Set has labels, Test does not.\n",
    "            label = self.df.iloc[idx, 1]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, -1  # X dont care for Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWeIlm3Ph8yd"
   },
   "outputs": [],
   "source": [
    "# Define MLP Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, layer1_size = 512, layer2_size = 256, dropout = 0.3):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, layer1_size)\n",
    "        self.bn1 = nn.BatchNorm1d(layer1_size)\n",
    "        self.fc2 = nn.Linear(layer1_size, layer2_size)\n",
    "        self.bn2 = nn.BatchNorm1d(layer2_size)\n",
    "        self.fc3 = nn.Linear(layer2_size, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNEntWEllnTv"
   },
   "outputs": [],
   "source": [
    "# Define transformations for better generalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(), # Random flipping left-right\n",
    "    transforms.RandomRotation(15), # Rotate randomly within ±15 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2), # Adjust brightness/contrast\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # Normalize\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # Flatten\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1KvaVlSnlpZ2"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into 3 (70% train, 10% val, 20% test)\n",
    "dataset = PokemonDataset(labels, image_folder, transform=transform)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3Xks2p8lsf5"
   },
   "outputs": [],
   "source": [
    "sample_image, _ = dataset[0]\n",
    "input_size = sample_image.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9jGeOKvskGD"
   },
   "outputs": [],
   "source": [
    "# Choose single hyperparameter values\n",
    "n_epochs = 50\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "step_size = 5\n",
    "l1_size = 256\n",
    "l2_size = 128\n",
    "dropout = 0.2\n",
    "gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9PDZUyLsoP6",
    "outputId": "43934f90-a1b4-438d-d8bc-ad2a3cfd1ad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1P975xls0vv"
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gSJEZ6ktDH0",
    "outputId": "552c55dc-fcfa-4f9e-e70c-adc94020acef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=16384, out_features=256, bias=True)\n",
       "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=128, out_features=9, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model, loss function, optimizer, and scheduler\n",
    "model = MLP(input_size, num_classes, l1_size, l2_size, dropout)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "pip_requirements = [\"torch==2.6.0+cu124\"]\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQmrzfQLD_Dr"
   },
   "outputs": [],
   "source": [
    "def log_gpu_usage():\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        mlflow.log_metric(f\"gpu_{i}_memory_used_MB\", gpu.memoryUsed)\n",
    "        mlflow.log_metric(f\"gpu_{i}_memory_total_MB\", gpu.memoryTotal)\n",
    "        mlflow.log_metric(f\"gpu_{i}_utilization_percent\", gpu.load * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35BmX7XwbNO9"
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def training_loop():\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(n_epochs):\n",
    "      model.train()\n",
    "      running_loss = 0.0\n",
    "      for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        log_gpu_usage()\n",
    "\n",
    "      # Validation loop\n",
    "      model.eval()\n",
    "      all_labels = []\n",
    "      all_preds = []\n",
    "      with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "          outputs = model(images)\n",
    "          _, preds = torch.max(outputs, 1)  # Get predicted class indices\n",
    "          all_labels.extend(labels.cpu().numpy())\n",
    "          all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "      # Calculate F1 Score\n",
    "      f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "      print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {running_loss/len(train_loader):.4f}, F1 Score: {f1:.4f}\")\n",
    "      mlflow.log_metric(\"loss\", f\"{running_loss/len(train_loader):.4f}\")\n",
    "      mlflow.log_metric(\"f1_score\", f\"{f1:.4f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Execution time: {execution_time} seconds\")\n",
    "\n",
    "    # Test loop\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "      for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "    mlflow.log_metric(\"eval_loss\", f\"{running_loss/len(train_loader):.4f}\")\n",
    "    mlflow.log_metric(\"eval_accuracy\", f\"{f1:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDpx6gDIxM21",
    "outputId": "51876326-5f42-4b40-c0ca-6945ab9a73c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.7945, F1 Score: 0.6038\n",
      "Epoch [2/50], Loss: 1.1560, F1 Score: 0.7473\n",
      "Epoch [3/50], Loss: 0.8610, F1 Score: 0.8037\n",
      "Epoch [4/50], Loss: 0.7759, F1 Score: 0.8614\n",
      "Epoch [5/50], Loss: 0.6254, F1 Score: 0.8584\n",
      "Epoch [6/50], Loss: 0.6012, F1 Score: 0.8861\n",
      "Epoch [7/50], Loss: 0.5411, F1 Score: 0.9050\n",
      "Epoch [8/50], Loss: 0.4887, F1 Score: 0.8796\n",
      "Epoch [9/50], Loss: 0.4683, F1 Score: 0.8832\n",
      "Epoch [10/50], Loss: 0.4411, F1 Score: 0.8971\n",
      "Epoch [11/50], Loss: 0.4448, F1 Score: 0.9051\n",
      "Epoch [12/50], Loss: 0.4428, F1 Score: 0.8965\n",
      "Epoch [13/50], Loss: 0.4110, F1 Score: 0.9081\n",
      "Epoch [14/50], Loss: 0.4131, F1 Score: 0.9029\n",
      "Epoch [15/50], Loss: 0.3781, F1 Score: 0.9110\n",
      "Epoch [16/50], Loss: 0.3888, F1 Score: 0.9188\n",
      "Epoch [17/50], Loss: 0.3914, F1 Score: 0.9167\n",
      "Epoch [18/50], Loss: 0.3534, F1 Score: 0.9011\n",
      "Epoch [19/50], Loss: 0.3478, F1 Score: 0.9026\n",
      "Epoch [20/50], Loss: 0.3580, F1 Score: 0.9149\n",
      "Epoch [21/50], Loss: 0.3539, F1 Score: 0.9111\n",
      "Epoch [22/50], Loss: 0.3297, F1 Score: 0.9093\n",
      "Epoch [23/50], Loss: 0.3345, F1 Score: 0.9095\n",
      "Epoch [24/50], Loss: 0.3212, F1 Score: 0.9096\n",
      "Epoch [25/50], Loss: 0.3328, F1 Score: 0.8997\n",
      "Epoch [26/50], Loss: 0.3343, F1 Score: 0.9051\n",
      "Epoch [27/50], Loss: 0.3391, F1 Score: 0.9129\n",
      "Epoch [28/50], Loss: 0.3220, F1 Score: 0.9185\n",
      "Epoch [29/50], Loss: 0.2933, F1 Score: 0.9090\n",
      "Epoch [30/50], Loss: 0.3032, F1 Score: 0.9068\n",
      "Epoch [31/50], Loss: 0.2975, F1 Score: 0.9116\n",
      "Epoch [32/50], Loss: 0.2915, F1 Score: 0.9243\n",
      "Epoch [33/50], Loss: 0.2874, F1 Score: 0.9144\n",
      "Epoch [34/50], Loss: 0.3161, F1 Score: 0.9077\n",
      "Epoch [35/50], Loss: 0.2905, F1 Score: 0.9207\n",
      "Epoch [36/50], Loss: 0.2887, F1 Score: 0.9089\n",
      "Epoch [37/50], Loss: 0.2959, F1 Score: 0.9183\n",
      "Epoch [38/50], Loss: 0.2834, F1 Score: 0.9214\n",
      "Epoch [39/50], Loss: 0.2436, F1 Score: 0.9132\n",
      "Epoch [40/50], Loss: 0.2830, F1 Score: 0.9185\n",
      "Epoch [41/50], Loss: 0.2648, F1 Score: 0.9066\n",
      "Epoch [42/50], Loss: 0.2602, F1 Score: 0.9164\n",
      "Epoch [43/50], Loss: 0.2547, F1 Score: 0.9147\n",
      "Epoch [44/50], Loss: 0.2454, F1 Score: 0.9177\n",
      "Epoch [45/50], Loss: 0.2728, F1 Score: 0.9107\n",
      "Epoch [46/50], Loss: 0.2578, F1 Score: 0.9171\n",
      "Epoch [47/50], Loss: 0.2705, F1 Score: 0.9077\n",
      "Epoch [48/50], Loss: 0.2582, F1 Score: 0.9113\n",
      "Epoch [49/50], Loss: 0.2542, F1 Score: 0.9141\n",
      "Epoch [50/50], Loss: 0.2530, F1 Score: 0.9008\n",
      "Execution time: 3709.7159385681152 seconds\n",
      "Test Accuracy: 90.37%\n",
      "Test F1 Score: 0.9022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/03/31 13:08:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "  params = {\n",
    "        \"epochs\": n_epochs,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"loss_function\": criterion.__class__.__name__,\n",
    "        \"metric_function\": f1_score.__name__,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"step_size\": step_size,\n",
    "        \"layer1_size\": l1_size,\n",
    "        \"layer2_size\": l2_size,\n",
    "        \"dropout\": dropout,\n",
    "        \"gamma\": gamma\n",
    "    }\n",
    "  output_folder = os.path.join(folder_path, \"outputs\")\n",
    "  if not os.path.exists(output_folder):\n",
    "      os.makedirs(output_folder)\n",
    "\n",
    "  # Log training parameters.\n",
    "  mlflow.log_params(params)\n",
    "\n",
    "  # Log model summary.\n",
    "  with open(os.path.join(output_folder, \"model_summary.txt\"), \"w\") as f:\n",
    "      f.write(str(summary(model)))\n",
    "\n",
    "  log_artifacts(output_folder)\n",
    "  mlflow.log_artifact(os.path.join(output_folder, \"model_summary.txt\"))\n",
    "\n",
    "  training_loop()\n",
    "\n",
    "  mlflow.pytorch.log_model(model, \"model\", pip_requirements=pip_requirements)#, input_example=sample_image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "homUnka8bNO-",
    "outputId": "daa4c976-5701-48c4-cc06-4fc4142656a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all registered models\n",
      "================================================================================\n",
      "{   'aliases': {},\n",
      "    'creation_timestamp': 1743092803691,\n",
      "    'description': None,\n",
      "    'last_updated_timestamp': 1743092803751,\n",
      "    'latest_versions': [   <ModelVersion: aliases=[], creation_timestamp=1743092803751, current_stage='None', description=None, last_updated_timestamp=1743092803751, name='MLP', run_id='b2e8bf02d84647068e8b6324abad84bf', run_link=None, source='/content/mlruns/1/b2e8bf02d84647068e8b6324abad84bf/artifacts/sklearn-model', status='READY', status_message=None, tags={}, user_id=None, version=1>],\n",
      "    'name': 'MLP',\n",
      "    'tags': {}}\n",
      "None\n",
      "\n",
      "List of Model = MLP and Versions\n",
      "================================================================================\n",
      "{   'aliases': [],\n",
      "    'creation_timestamp': 1743092803751,\n",
      "    'current_stage': 'None',\n",
      "    'description': None,\n",
      "    'last_updated_timestamp': 1743092803751,\n",
      "    'name': 'MLP',\n",
      "    'run_id': 'b2e8bf02d84647068e8b6324abad84bf',\n",
      "    'run_link': None,\n",
      "    'source': '/content/mlruns/1/b2e8bf02d84647068e8b6324abad84bf/artifacts/sklearn-model',\n",
      "    'status': 'READY',\n",
      "    'status_message': None,\n",
      "    'tags': {},\n",
      "    'user_id': None,\n",
      "    'version': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "\n",
    "print(\"List of all registered models\")\n",
    "print(\"=\" * 80)\n",
    "[print(pprint.pprint(dict(rm), indent=4)) for rm in client.search_registered_models()]\n",
    "\n",
    "# Get a list of specific versions of the named models\n",
    "print(f\"\\nList of Model = {model_name} and Versions\")\n",
    "print(\"=\" * 80)\n",
    "[pprint.pprint(dict(mv), indent=4) for mv in client.search_model_versions()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3rH6P_zRMul"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "APenv",
   "language": "python",
   "name": "apenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
